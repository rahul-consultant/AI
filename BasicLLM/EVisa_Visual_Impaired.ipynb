{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c1dfe8f-da0f-4347-a7c2-e8101509f796",
   "metadata": {},
   "source": [
    "## This is automated visa application processing system using AI.\n",
    "\n",
    "##### This project will use multi AI model which will assist visually impaired person in filling Visa. Capture his image and then transform into EVisa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "401befbe-82d0-4f3b-82ab-c1f8eb6051c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from IPython.display import Audio, display\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55c8ccb6-d413-4855-beda-c5ef0bf318da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "MODEL = \"gpt-4o-mini\"\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18a5e905-fdf7-45cc-a8b0-1b83ccd472c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "def talker(message):\n",
    "    response = openai.audio.speech.create(\n",
    "      model=\"tts-1\",\n",
    "      voice=\"onyx\",    # Also, try replacing onyx with alloy\n",
    "      input=message\n",
    "    )\n",
    "    \n",
    "    audio_stream = BytesIO(response.content)\n",
    "    audio = AudioSegment.from_file(audio_stream, format=\"mp3\")\n",
    "    play(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "405e7a42-3a3a-4f6d-8ba4-3ada95e66483",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant for an E Visa application called Eazee. \"\n",
    "system_message += \"Give short, courteous answers, no more than 1 sentence. \"\n",
    "system_message += \"Always be accurate. If you don't know the answer, say so.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a3b00fe-139b-476a-a1cc-fbae8118d1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7876\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7876/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from fpdf import FPDF\n",
    "import cv2\n",
    "import gradio as gr\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import time\n",
    "\n",
    "# --- Initialization ---\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "openai = OpenAI(api_key=openai_api_key)\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "def talker(message):\n",
    "    response = openai.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"onyx\",\n",
    "        input=message\n",
    "    )\n",
    "    audio_stream = BytesIO(response.content)\n",
    "    audio = AudioSegment.from_file(audio_stream, format=\"mp3\")\n",
    "    play(audio)\n",
    "\n",
    "def auto_capture_photo(img_path=\"visa_photo.jpg\"):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        raise Exception(\"Could not open camera\")\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    if not ret:\n",
    "        raise Exception(\"Failed to capture image\")\n",
    "    cv2.imwrite(img_path, frame)\n",
    "    # Encode image as base64\n",
    "    with open(img_path, \"rb\") as f:\n",
    "        photo_b64 = base64.b64encode(f.read()).decode()\n",
    "    return img_path, photo_b64\n",
    "\n",
    "def create_visa_application_pdf(firstname, lastname, address, gender, img_path):\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", size=14)\n",
    "    pdf.cell(200, 10, \"E-Visa Application Form\", ln=True, align=\"C\")\n",
    "    pdf.ln(10)\n",
    "    pdf.cell(50, 10, f\"First Name: {firstname}\", ln=True)\n",
    "    pdf.cell(50, 10, f\"Last Name: {lastname}\", ln=True)\n",
    "    pdf.cell(50, 10, f\"Gender: {gender}\", ln=True)\n",
    "    pdf.multi_cell(0, 10, f\"Address: {address}\", align=\"L\")\n",
    "    pdf.ln(10)\n",
    "    pdf.cell(50, 10, \"Applicant Photo:\", ln=True)\n",
    "    if os.path.exists(img_path):\n",
    "        pdf.image(img_path, x=pdf.get_x(), y=pdf.get_y(), w=40)\n",
    "    pdf_path = \"visa_application.pdf\"\n",
    "    pdf.output(pdf_path)\n",
    "    return pdf_path\n",
    "\n",
    "Visa_function = {\n",
    "    \"name\": \"create_visa_application_pdf\",\n",
    "    \"description\": (\n",
    "        \"Generate a visa application PDF. \"\n",
    "        \"Call this whenever you need to create a visa application, for example when a customer asks 'Can you help with my visa application?'\"\n",
    "    ),\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"firstname\": {\"type\": \"string\", \"description\": \"The applicant's first name\"},\n",
    "            \"lastname\": {\"type\": \"string\", \"description\": \"The applicant's last name\"},\n",
    "            \"address\": {\"type\": \"string\", \"description\": \"The applicant's address\"},\n",
    "            \"gender\": {\"type\": \"string\", \"description\": \"The applicant's gender\"},\n",
    "            \"photo\": {\"type\": \"string\", \"description\": \"Base64-encoded image of the applicant's photo\"}\n",
    "        },\n",
    "        \"required\": [\"firstname\", \"lastname\", \"address\", \"gender\", \"photo\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "tools = [{\"type\": \"function\", \"function\": Visa_function}]\n",
    "\n",
    "def handle_tool_call(tool_call):\n",
    "    args = json.loads(tool_call.function.arguments)\n",
    "    firstname = args.get(\"firstname\")\n",
    "    lastname = args.get(\"lastname\")\n",
    "    address = args.get(\"address\")\n",
    "    gender = args.get(\"gender\")\n",
    "    photo_b64 = args.get(\"photo\")\n",
    "    img_path = \"visa_photo.jpg\"\n",
    "    with open(img_path, \"wb\") as f:\n",
    "        f.write(base64.b64decode(photo_b64))\n",
    "    pdf_path = create_visa_application_pdf(firstname, lastname, address, gender, img_path)\n",
    "    return pdf_path\n",
    "\n",
    "def chat_with_openai(audio_input, history, photo_b64):\n",
    "    user_text = \"\"\n",
    "    if audio_input is not None:\n",
    "        import speech_recognition as sr\n",
    "        recognizer = sr.Recognizer()\n",
    "        with sr.AudioFile(audio_input) as source:\n",
    "            audio = recognizer.record(source)\n",
    "        try:\n",
    "            user_text = recognizer.recognize_google(audio)\n",
    "        except Exception:\n",
    "            user_text = \"\"\n",
    "    if not user_text:\n",
    "        user_text = \" \"  # Avoid empty input\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant for E-Visa applications. Collect all required info and call the function when ready.\"}]\n",
    "    messages += history\n",
    "    messages.append({\"role\": \"user\", \"content\": user_text})\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "    reply = response.choices[0].message\n",
    "\n",
    "    # Speak the assistant's reply\n",
    "    if reply.content:\n",
    "        talker(reply.content)\n",
    "\n",
    "    # If OpenAI wants to call the function\n",
    "    if reply.tool_calls:\n",
    "        tool_call = reply.tool_calls[0]\n",
    "        args = json.loads(tool_call.function.arguments)\n",
    "        if not args.get(\"photo\") and not photo_b64:\n",
    "            talker(\"I will now take your photo. Please look at the camera.\")\n",
    "            img_path, photo_b64 = auto_capture_photo()\n",
    "            args[\"photo\"] = photo_b64\n",
    "            pdf_path = handle_tool_call(tool_call)\n",
    "            talker(\"Your visa application is ready. You can download it now.\")\n",
    "            return messages, photo_b64, pdf_path, \"Your visa application is ready. Download below.\", gr.update(value=None)\n",
    "        elif not args.get(\"photo\"):\n",
    "            args[\"photo\"] = photo_b64\n",
    "        pdf_path = handle_tool_call(tool_call)\n",
    "        talker(\"Your visa application is ready. You can download it now.\")\n",
    "        return messages, photo_b64, pdf_path, \"Your visa application is ready. Download below.\", gr.update(value=None)\n",
    "    else:\n",
    "        return messages, photo_b64, None, reply.content, gr.update(value=None)\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Eazee: Voice-Driven E-Visa Assistant for the Visually Impaired\")\n",
    "    history = gr.State([])\n",
    "    photo_b64 = gr.State(None)\n",
    "    audio_input = gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"Speak to the assistant\", autoplay=True, streaming=True)\n",
    "    output_text = gr.Textbox(label=\"Assistant\", interactive=False)\n",
    "    pdf_file = gr.File(label=\"Download Visa Application PDF\")\n",
    "\n",
    "    def auto_submit(audio, history, photo_b64):\n",
    "        # Wait a moment to simulate \"pause\" after recording\n",
    "        time.sleep(1.5)\n",
    "        return chat_with_openai(audio, history, photo_b64)\n",
    "\n",
    "    audio_input.change(\n",
    "        auto_submit,\n",
    "        inputs=[audio_input, history, photo_b64],\n",
    "        outputs=[history, photo_b64, pdf_file, output_text, audio_input]\n",
    "    )\n",
    "\n",
    "    # Optionally, add a manual button for fallback\n",
    "    gr.Markdown(\"If you need to repeat, just speak again.\")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f07cb17-302c-49dc-bb19-fad9e84913e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from fpdf import FPDF\n",
    "import cv2\n",
    "import gradio as gr\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import time\n",
    "\n",
    "\n",
    "# --- Initialization ---\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "openai = OpenAI(api_key=openai_api_key)\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "def talker(message):\n",
    "    response = openai.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"onyx\",\n",
    "        input=message\n",
    "    )\n",
    "    audio_stream = BytesIO(response.content)\n",
    "    audio = AudioSegment.from_file(audio_stream, format=\"mp3\")\n",
    "    play(audio)\n",
    "\n",
    "def auto_capture_photo(img_path=\"visa_photo.jpg\"):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        raise Exception(\"Could not open camera\")\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    if not ret:\n",
    "        raise Exception(\"Failed to capture image\")\n",
    "    cv2.imwrite(img_path, frame)\n",
    "    # Encode image as base64\n",
    "    with open(img_path, \"rb\") as f:\n",
    "        photo_b64 = base64.b64encode(f.read()).decode()\n",
    "    return img_path, photo_b64\n",
    "\n",
    "def create_visa_application_pdf(firstname, lastname, address, gender, img_path):\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", size=14)\n",
    "    pdf.cell(200, 10, \"E-Visa Application Form\", ln=True, align=\"C\")\n",
    "    pdf.ln(10)\n",
    "    pdf.cell(50, 10, f\"First Name: {firstname}\", ln=True)\n",
    "    pdf.cell(50, 10, f\"Last Name: {lastname}\", ln=True)\n",
    "    pdf.cell(50, 10, f\"Gender: {gender}\", ln=True)\n",
    "    pdf.multi_cell(0, 10, f\"Address: {address}\", align=\"L\")\n",
    "    pdf.ln(10)\n",
    "    pdf.cell(50, 10, \"Applicant Photo:\", ln=True)\n",
    "    if os.path.exists(img_path):\n",
    "        pdf.image(img_path, x=pdf.get_x(), y=pdf.get_y(), w=40)\n",
    "    pdf_path = \"visa_application.pdf\"\n",
    "    pdf.output(pdf_path)\n",
    "    return pdf_path\n",
    "\n",
    "Visa_function = {\n",
    "    \"name\": \"create_visa_application_pdf\",\n",
    "    \"description\": (\n",
    "        \"Generate a visa application PDF. \"\n",
    "        \"Call this whenever you need to create a visa application, for example when a customer asks 'Can you help with my visa application?'\"\n",
    "    ),\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"firstname\": {\"type\": \"string\", \"description\": \"The applicant's first name\"},\n",
    "            \"lastname\": {\"type\": \"string\", \"description\": \"The applicant's last name\"},\n",
    "            \"address\": {\"type\": \"string\", \"description\": \"The applicant's address\"},\n",
    "            \"gender\": {\"type\": \"string\", \"description\": \"The applicant's gender\"},\n",
    "            \"photo\": {\"type\": \"string\", \"description\": \"Base64-encoded image of the applicant's photo\"}\n",
    "        },\n",
    "        \"required\": [\"firstname\", \"lastname\", \"address\", \"gender\", \"photo\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "tools = [{\"type\": \"function\", \"function\": Visa_function}]\n",
    "\n",
    "def handle_tool_call(tool_call):\n",
    "    args = json.loads(tool_call.function.arguments)\n",
    "    firstname = args.get(\"firstname\")\n",
    "    lastname = args.get(\"lastname\")\n",
    "    address = args.get(\"address\")\n",
    "    gender = args.get(\"gender\")\n",
    "    photo_b64 = args.get(\"photo\")\n",
    "    img_path = \"visa_photo.jpg\"\n",
    "    with open(img_path, \"wb\") as f:\n",
    "        f.write(base64.b64decode(photo_b64))\n",
    "    pdf_path = create_visa_application_pdf(firstname, lastname, address, gender, img_path)\n",
    "    return pdf_path\n",
    "\n",
    "# --- Main Chat Logic ---\n",
    "def chat_with_openai(audio_input, history, photo_b64, collected):\n",
    "    # Transcribe audio to text\n",
    "   \n",
    "    user_text = \"\"\n",
    "    if audio_input is not None:\n",
    "        import speech_recognition as sr\n",
    "        recognizer = sr.Recognizer()\n",
    "        with sr.AudioFile(audio_input) as source:\n",
    "            audio = recognizer.record(source)\n",
    "        try:\n",
    "            user_text = recognizer.recognize_google(audio)\n",
    "            print(f\"User said: {user_text}\")\n",
    "        except Exception:\n",
    "            user_text = \"\"\n",
    "    if not user_text:\n",
    "        user_text = \" \"  # Avoid empty input\n",
    "\n",
    "    # Initialize collected fields if needed\n",
    "    if not collected:\n",
    "        collected = {\"firstname\": None, \"lastname\": None, \"address\": None, \"gender\": None}\n",
    "\n",
    "    # Try to extract fields from user_text\n",
    "    text = user_text.lower()\n",
    "    if not collected[\"firstname\"] and \"first name\" in text:\n",
    "        collected[\"firstname\"] = user_text.split(\"first name\")[-1].strip(\":,. \")\n",
    "    elif not collected[\"lastname\"] and \"last name\" in text:\n",
    "        collected[\"lastname\"] = user_text.split(\"last name\")[-1].strip(\":,. \")\n",
    "    elif not collected[\"address\"] and \"address\" in text:\n",
    "        collected[\"address\"] = user_text.split(\"address\")[-1].strip(\":,. \")\n",
    "    elif not collected[\"gender\"] and \"gender\" in text:\n",
    "        collected[\"gender\"] = user_text.split(\"gender\")[-1].strip(\":,. \")\n",
    "        print(user_text.split(\"gender\")[-1].strip(\":,. \"))\n",
    "    # Or, just take the answer in order if the assistant just asked for it:\n",
    "    elif history:\n",
    "        last_assistant = history[-1][1].lower() if isinstance(history[-1], (list, tuple)) else \"\"\n",
    "        if \"first name\" in last_assistant and not collected[\"firstname\"]:\n",
    "            collected[\"firstname\"] = user_text.strip()\n",
    "        elif \"last name\" in last_assistant and not collected[\"lastname\"]:\n",
    "            collected[\"lastname\"] = user_text.strip()\n",
    "        elif \"address\" in last_assistant and not collected[\"address\"]:\n",
    "            collected[\"address\"] = user_text.strip()\n",
    "        elif \"gender\" in last_assistant and not collected[\"gender\"]:\n",
    "            collected[\"gender\"] = user_text.strip()\n",
    "            print(user_text.strip())\n",
    "\n",
    "    # If all fields are collected, take photo and generate PDF\n",
    "    if all(collected.values()):\n",
    "        talker(\"Thank you. I will now take your photo. Please look at the camera.\")\n",
    "        img_path, photo_b64 = auto_capture_photo()\n",
    "        pdf_path = create_visa_application_pdf(\n",
    "            collected[\"firstname\"], collected[\"lastname\"], collected[\"address\"], collected[\"gender\"], img_path\n",
    "        )\n",
    "        talker(\"Your visa application is ready. You can download it now.\")\n",
    "        return [], photo_b64, pdf_path, \"Your visa application is ready. Download below.\", collected\n",
    "\n",
    "    # Otherwise, continue dialog with OpenAI\n",
    "    # Compose prompt with only missing fields\n",
    "    missing = [k for k, v in collected.items() if not v]\n",
    "    if not history:\n",
    "        greeting = \"Welcome to Eazee! I will help you fill out your visa application. What is your first name?\"\n",
    "        talker(greeting)\n",
    "        return [[user_text, greeting]], photo_b64, None, greeting, collected\n",
    "\n",
    "    # Compose system prompt\n",
    "    system_prompt = (\n",
    "        \"You are a helpful assistant for E-Visa applications. \"\n",
    "        \"Collect only first name, last name, address, and gender. \"\n",
    "        \"Do not ask for or mention photo. \"\n",
    "        \"Ask for only one missing field at a time.\"\n",
    "    )\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    for h in history:\n",
    "        if isinstance(h, (list, tuple)) and len(h) == 2:\n",
    "            messages.append({\"role\": \"user\", \"content\": h[0]})\n",
    "            messages.append({\"role\": \"assistant\", \"content\": h[1]})\n",
    "    messages.append({\"role\": \"user\", \"content\": user_text})\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages\n",
    "    )\n",
    "    reply = response.choices[0].message.content\n",
    "    talker(reply)\n",
    "    history.append([user_text, reply])\n",
    "    return history, photo_b64, None, reply, collected\n",
    "\n",
    "# --- Gradio UI ---\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Eazee: Voice-Driven E-Visa Assistant for the Visually Impaired\")\n",
    "    history = gr.State([])\n",
    "    photo_b64 = gr.State(None)\n",
    "    collected = gr.State({})\n",
    "    audio_input = gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"Speak to the assistant\")\n",
    "    output_text = gr.Textbox(label=\"Assistant\", interactive=False)\n",
    "    pdf_file = gr.File(label=\"Download Visa Application PDF\")\n",
    "    submit = gr.Button(\"Submit/Continue\")\n",
    "    submit.click(\n",
    "        chat_with_openai,\n",
    "        inputs=[audio_input, history, photo_b64, collected],\n",
    "        outputs=[history, photo_b64, pdf_file, output_text, collected]\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c91759-3973-4890-9d61-9e74c393562e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
